{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royryo/Household-Energy-Load-Forecast/blob/main/Cam_Ryo_Maddie_with_feedback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All comments below are proceeded with ': GA' and there is a final 'additional comments' section with grade"
      ],
      "metadata": {
        "id": "mRMyOs0NCJmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the enviroment\n",
        "We first installed all required packages and imported them. Then, we queried how many insertions and sessions there are. The IBL reproducible electrophysiology dataset has EIDS and PIDS, which identifies the specific probe in a session and the entire recording session. We had 83 insertions and 83 sessions. We chose the first insertion, which had data for the visual cortex, CA1 hippocampus, and thalamusâ€”the brain regions we were interested in. We sampled all 83 sessions. We loaded all neural data and obtained the indicies for specific brain regions. "
      ],
      "metadata": {
        "id": "21RJnx0ZBhIo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klbBkBIjBYYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d41492-fefa-489a-db31-25a33381c686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ONE-api in /usr/local/lib/python3.8/dist-packages (1.16.3)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.8/dist-packages (from ONE-api) (1.21.6)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.8/dist-packages (from ONE-api) (1.26.34)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from ONE-api) (6.0)\n",
            "Requirement already satisfied: iblutil>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from ONE-api) (1.4.0)\n",
            "Requirement already satisfied: flake8>=3.7.8 in /usr/local/lib/python3.8/dist-packages (from ONE-api) (6.0.0)\n",
            "Requirement already satisfied: tqdm>=4.32.1 in /usr/local/lib/python3.8/dist-packages (from ONE-api) (4.64.1)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.8/dist-packages (from ONE-api) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.8/dist-packages (from ONE-api) (2.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from ONE-api) (21.3)\n",
            "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from flake8>=3.7.8->ONE-api) (0.7.0)\n",
            "Requirement already satisfied: pycodestyle<2.11.0,>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from flake8>=3.7.8->ONE-api) (2.10.0)\n",
            "Requirement already satisfied: pyflakes<3.1.0,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from flake8>=3.7.8->ONE-api) (3.0.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from iblutil>=1.1.0->ONE-api) (0.56.4)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.8/dist-packages (from iblutil>=1.1.0->ONE-api) (9.0.0)\n",
            "Requirement already satisfied: colorlog>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from iblutil>=1.1.0->ONE-api) (6.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.4->ONE-api) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.4->ONE-api) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.4->ONE-api) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->ONE-api) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->ONE-api) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->ONE-api) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->ONE-api) (2.1.1)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from boto3->ONE-api) (1.0.1)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.34 in /usr/local/lib/python3.8/dist-packages (from boto3->ONE-api) (1.29.34)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from boto3->ONE-api) (0.6.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->iblutil>=1.1.0->ONE-api) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba->iblutil>=1.1.0->ONE-api) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba->iblutil>=1.1.0->ONE-api) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba->iblutil>=1.1.0->ONE-api) (3.11.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->ONE-api) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ibllib in /usr/local/lib/python3.8/dist-packages (2.19.0)\n",
            "Requirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from ibllib) (0.11.2)\n",
            "Requirement already satisfied: nptdms in /usr/local/lib/python3.8/dist-packages (from ibllib) (1.6.0)\n",
            "Requirement already satisfied: slidingRP>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ibllib) (1.0.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.8/dist-packages (from ibllib) (9.0.0)\n",
            "Requirement already satisfied: wfield>=0.3.6 in /usr/local/lib/python3.8/dist-packages (from ibllib) (0.3.7)\n",
            "Requirement already satisfied: jupyter>=1.0 in /usr/local/lib/python3.8/dist-packages (from ibllib) (1.0.0)\n",
            "Requirement already satisfied: phylib>=2.4 in /usr/local/lib/python3.8/dist-packages (from ibllib) (2.4.2)\n",
            "Requirement already satisfied: iblutil>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from ibllib) (1.4.0)\n",
            "Requirement already satisfied: ibl-neuropixel>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from ibllib) (0.4.1)\n",
            "Requirement already satisfied: pynrrd>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from ibllib) (1.0.0)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.8/dist-packages (from ibllib) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.8/dist-packages (from ibllib) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.32.1 in /usr/local/lib/python3.8/dist-packages (from ibllib) (4.64.1)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from ibllib) (1.7.3)\n",
            "Requirement already satisfied: mtscomp>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from ibllib) (1.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.8/dist-packages (from ibllib) (1.0.2)\n",
            "Requirement already satisfied: colorlog>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from ibllib) (6.7.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from ibllib) (4.6.0.66)\n",
            "Requirement already satisfied: ONE-api>=1.16.1 in /usr/local/lib/python3.8/dist-packages (from ibllib) (1.16.3)\n",
            "Requirement already satisfied: numba>=0.56 in /usr/local/lib/python3.8/dist-packages (from ibllib) (0.56.4)\n",
            "Requirement already satisfied: labcams in /usr/local/lib/python3.8/dist-packages (from ibllib) (0.6.5)\n",
            "Requirement already satisfied: click>=7.0.0 in /usr/local/lib/python3.8/dist-packages (from ibllib) (7.1.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.8/dist-packages (from ibllib) (1.26.34)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.8/dist-packages (from ibllib) (3.6.4)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from ibllib) (0.10.1)\n",
            "Requirement already satisfied: flake8>=3.7.8 in /usr/local/lib/python3.8/dist-packages (from ibllib) (6.0.0)\n",
            "Requirement already satisfied: globus-sdk==3.2.1 in /usr/local/lib/python3.8/dist-packages (from ibllib) (3.2.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.8/dist-packages (from ibllib) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.8/dist-packages (from ibllib) (2.28.1)\n",
            "Requirement already satisfied: jupyterlab>=1.0 in /usr/local/lib/python3.8/dist-packages (from ibllib) (3.5.2)\n",
            "Requirement already satisfied: cryptography!=3.4.0,>=3.3.1 in /usr/local/lib/python3.8/dist-packages (from globus-sdk==3.2.1->ibllib) (38.0.4)\n",
            "Requirement already satisfied: pyjwt[crypto]<3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from globus-sdk==3.2.1->ibllib) (2.6.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography!=3.4.0,>=3.3.1->globus-sdk==3.2.1->ibllib) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography!=3.4.0,>=3.3.1->globus-sdk==3.2.1->ibllib) (2.21)\n",
            "Requirement already satisfied: pyflakes<3.1.0,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from flake8>=3.7.8->ibllib) (3.0.1)\n",
            "Requirement already satisfied: pycodestyle<2.11.0,>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from flake8>=3.7.8->ibllib) (2.10.0)\n",
            "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from flake8>=3.7.8->ibllib) (0.7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from ibl-neuropixel>=0.4.0->ibllib) (1.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0->ibllib) (7.7.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0->ibllib) (5.3.4)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0->ibllib) (7.2.7)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0->ibllib) (6.5.2)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0->ibllib) (6.1.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0->ibllib) (5.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from jupyterlab>=1.0->ibllib) (21.3)\n",
            "Requirement already satisfied: nbclassic in /usr/local/lib/python3.8/dist-packages (from jupyterlab>=1.0->ibllib) (0.4.8)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from jupyterlab>=1.0->ibllib) (7.9.0)\n",
            "Requirement already satisfied: jupyterlab-server~=2.10 in /usr/local/lib/python3.8/dist-packages (from jupyterlab>=1.0->ibllib) (2.16.5)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from jupyterlab>=1.0->ibllib) (2.0.2)\n",
            "Requirement already satisfied: jinja2>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyterlab>=1.0->ibllib) (3.1.2)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.8/dist-packages (from jupyterlab>=1.0->ibllib) (2.0.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from jupyterlab>=1.0->ibllib) (5.1.0)\n",
            "Requirement already satisfied: tornado>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from jupyterlab>=1.0->ibllib) (6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.1->jupyterlab>=1.0->ibllib) (2.0.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (0.15.0)\n",
            "Requirement already satisfied: traitlets>=5.6.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (5.7.1)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.8/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (24.0.1)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (5.7.0)\n",
            "Requirement already satisfied: jupyter-events>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (0.5.0)\n",
            "Requirement already satisfied: jupyter-server-terminals in /usr/local/lib/python3.8/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (0.4.3)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.8/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (1.4.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (0.13.3)\n",
            "Requirement already satisfied: jupyter-client>=7.4.4 in /usr/local/lib/python3.8/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (7.4.8)\n",
            "Requirement already satisfied: send2trash in /usr/local/lib/python3.8/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (1.8.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (3.6.2)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.8/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (21.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.8/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (2.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.8/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (2.8.2)\n",
            "Requirement already satisfied: nest-asyncio>=1.5.4 in /usr/local/lib/python3.8/dist-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (1.5.6)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (0.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->jupyterlab>=1.0->ibllib) (2.6.0)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.8/dist-packages (from jupyter-events>=0.4.0->jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (2.0.4)\n",
            "Requirement already satisfied: jsonschema[format-nongpl]>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-events>=0.4.0->jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (4.3.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from jupyter-events>=0.4.0->jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (6.0)\n",
            "\u001b[33mWARNING: jsonschema 4.3.3 does not provide the extra 'format-nongpl'\u001b[0m\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema[format-nongpl]>=4.3.0->jupyter-events>=0.4.0->jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (22.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema[format-nongpl]>=4.3.0->jupyter-events>=0.4.0->jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (0.19.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema[format-nongpl]>=4.3.0->jupyter-events>=0.4.0->jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (5.10.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema[format-nongpl]>=4.3.0->jupyter-events>=0.4.0->jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (3.11.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from jupyterlab-server~=2.10->jupyterlab>=1.0->ibllib) (0.9.10)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.8/dist-packages (from jupyterlab-server~=2.10->jupyterlab>=1.0->ibllib) (2.11.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.8/dist-packages (from jupyterlab-server~=2.10->jupyterlab>=1.0->ibllib) (5.1.0)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.8/dist-packages (from babel>=2.10->jupyterlab-server~=2.10->jupyterlab>=1.0->ibllib) (2022.6)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.3->ibllib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.3->ibllib) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.3->ibllib) (0.11.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0->ibllib) (5.0.1)\n",
            "Requirement already satisfied: mistune<3,>=2.0.3 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0->ibllib) (2.0.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0->ibllib) (1.5.0)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0->ibllib) (2.6.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0->ibllib) (0.7.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0->ibllib) (1.2.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0->ibllib) (0.2.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0->ibllib) (0.7.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0->ibllib) (4.6.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (2.16.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter>=1.0->ibllib) (0.2.0)\n",
            "Requirement already satisfied: notebook-shim>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from nbclassic->jupyterlab>=1.0->ibllib) (0.2.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.56->ibllib) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.56->ibllib) (57.4.0)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.8/dist-packages (from phylib>=2.4->ibllib) (2022.2.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from phylib>=2.4->ibllib) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from pynrrd>=0.4.0->ibllib) (4.4.0)\n",
            "Requirement already satisfied: nptyping in /usr/local/lib/python3.8/dist-packages (from pynrrd>=0.4.0->ibllib) (2.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=7.4.4->jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (1.15.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->ibllib) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->ibllib) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->ibllib) (2022.12.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->ibllib) (3.1.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (0.7.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from wfield>=0.3.6->ibllib) (7.1.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from wfield>=0.3.6->ibllib) (0.18.3)\n",
            "Requirement already satisfied: scikit-video in /usr/local/lib/python3.8/dist-packages (from wfield>=0.3.6->ibllib) (1.1.11)\n",
            "Requirement already satisfied: pyqtwebengine in /usr/local/lib/python3.8/dist-packages (from wfield>=0.3.6->ibllib) (5.15.6)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.8/dist-packages (from wfield>=0.3.6->ibllib) (5.5.0)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.8/dist-packages (from wfield>=0.3.6->ibllib) (2022.10.10)\n",
            "Requirement already satisfied: pyqt5 in /usr/local/lib/python3.8/dist-packages (from wfield>=0.3.6->ibllib) (5.15.7)\n",
            "Requirement already satisfied: pyqtgraph in /usr/local/lib/python3.8/dist-packages (from wfield>=0.3.6->ibllib) (0.13.1)\n",
            "Requirement already satisfied: pims in /usr/local/lib/python3.8/dist-packages (from wfield>=0.3.6->ibllib) (0.6.1)\n",
            "Requirement already satisfied: pyserial in /usr/local/lib/python3.8/dist-packages (from wfield>=0.3.6->ibllib) (3.5)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.8/dist-packages (from argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab>=1.0->ibllib) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->jupyter>=1.0->ibllib) (0.5.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from boto3->ibllib) (0.6.0)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.34 in /usr/local/lib/python3.8/dist-packages (from boto3->ibllib) (1.29.34)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from boto3->ibllib) (1.0.1)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask->phylib>=2.4->ibllib) (1.3.0)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from dask->phylib>=2.4->ibllib) (1.5.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from dask->phylib>=2.4->ibllib) (2022.11.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.8/dist-packages (from partd>=0.3.10->dask->phylib>=2.4->ibllib) (1.0.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab>=1.0->ibllib) (0.2.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab>=1.0->ibllib) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab>=1.0->ibllib) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab>=1.0->ibllib) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab>=1.0->ibllib) (2.0.10)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab>=1.0->ibllib) (0.7.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->jupyterlab>=1.0->ibllib) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->jupyterlab>=1.0->ibllib) (0.2.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter>=1.0->ibllib) (3.0.4)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter>=1.0->ibllib) (3.6.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (from pims->wfield>=0.3.6->ibllib) (2.9.0)\n",
            "Requirement already satisfied: slicerator>=0.9.8 in /usr/local/lib/python3.8/dist-packages (from pims->wfield>=0.3.6->ibllib) (1.1.0)\n",
            "Requirement already satisfied: PyQt5-sip<13,>=12.11 in /usr/local/lib/python3.8/dist-packages (from pyqt5->wfield>=0.3.6->ibllib) (12.11.0)\n",
            "Requirement already satisfied: PyQt5-Qt5>=5.15.0 in /usr/local/lib/python3.8/dist-packages (from pyqt5->wfield>=0.3.6->ibllib) (5.15.2)\n",
            "Requirement already satisfied: PyQtWebEngine-Qt5>=5.15.0 in /usr/local/lib/python3.8/dist-packages (from pyqtwebengine->wfield>=0.3.6->ibllib) (5.15.2)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.8/dist-packages (from pytest->ibllib) (1.4.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytest->ibllib) (9.0.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.8/dist-packages (from pytest->ibllib) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from pytest->ibllib) (1.11.0)\n",
            "Requirement already satisfied: qtpy>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from qtconsole->jupyter>=1.0->ibllib) (2.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->wfield>=0.3.6->ibllib) (2.8.8)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->wfield>=0.3.6->ibllib) (1.4.1)\n"
          ]
        }
      ],
      "source": [
        "# @title Installing packages and importing libraries\n",
        "\n",
        "! pip install ONE-api\n",
        "! pip install ibllib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from brainbox.io.one import SpikeSortingLoader\n",
        "from brainbox.plot import peri_event_time_histogram\n",
        "from brainbox.singlecell import calculate_peths\n",
        "\n",
        "from ibllib.atlas import AllenAtlas\n",
        "from one.api import ONE\n",
        "\n",
        "from brainbox.population import decode\n",
        "from matplotlib.axis import YAxis\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, LinearRegression, Lasso\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "one = ONE(base_url='https://openalyx.internationalbrainlab.org', password='international', silent=True)\n",
        "ba = AllenAtlas()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Finding the number of insertions and sessions\n",
        "\n",
        "insertions = one.alyx.rest('insertions', 'list', django='datasets__tags__name,2022_Q2_IBL_et_al_RepeatedSite')\n",
        "pids = [i['id'] for i in insertions]\n",
        "print(f'Found {len(insertions)} insertions')\n",
        "\n",
        "#sessions = one.alyx.rest('sessions', 'list', tag='2022_Q2_IBL_et_al_RepeatedSite')\n",
        "#eids = [i['id'] for i in sessions]\n",
        "#print(f'Found {len(sessions)} sessions')"
      ],
      "metadata": {
        "id": "dDMH1Y56ssUd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6844583-efe0-4fca-a4b7-903acf6cce19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 83 insertions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Data retrival and loading \n",
        "\n",
        "# Load in the neural data of the first insertion\n",
        "sl = SpikeSortingLoader(pid=pids[0],  one=one, atlas=ba)\n",
        "spikes, clusters, channels = sl.load_spike_sorting()\n",
        "clusters = sl.merge_clusters(spikes, clusters, channels)\n",
        "\n",
        "# Get the neuron indices\n",
        "VIS_neurons = [i for i, acronym in enumerate(clusters['acronym']) if 'VIS' in acronym]\n",
        "CA1_neurons = [i for i, acronym in enumerate(clusters['acronym']) if 'CA1' in acronym]\n",
        "PO_neurons = [i for i, acronym in enumerate(clusters['acronym']) if 'PO' in acronym]\n"
      ],
      "metadata": {
        "id": "enxF2KgQumg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions\n",
        "We then developed functions for obtaining the correlation coefficient matrix and predicting the weights of our model. Our null model is the accuracy of the choice, which is represented as feedback type or whether the mice received a reward or not. The IBL website indicates that the feedback type has values +1, 0, -1 or reward, no choice, or no reward, there was no 0 over 83 sessions. Variables we used for the logisic regression were the activity of three brain regions and the feedback type for the mice's choice. The hyperparameters we chose for the cross-validation was K-Fold split of 5. We did not use any regularization because the null model and the accuracy of our model were similar **(This is not a good justification for not using regularization - it could be that the accuracies are similar because no regularization was used. It is possible that your argument may hold if you are talking about train accuracy (as opposed to test accuracy); a better justification would be that there are very few regressors in comparison to the number of samples, thus overfitting is unlikely: GA)**. The time intervals we binned was 20 ms until 400 ms **(this is a hyperparameter that should be justified, especially because the pre-stimulus period may be as short as 200 ms: GA)** before the stimulus onset to assess the co-activation between the brain regions if they are important for response. We modified our data by making a correlation coefficient matrix, where each diagonal element was the average activity of a brain region across time. The t-test was used to determine the signifance of the weights predicted to the null model. \n",
        "\n"
      ],
      "metadata": {
        "id": "AqOmy4lsleih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function calculates the correlation coefficient matrix of three brain regions. We chose the visual cortex, thalamus, and CA1 hippocampus. The function gets the matrix of size of the length of trials by the correlation between brain regions and itself. The function replaces the diagonal elements of the matrix with the average activity of the brain region to also predict the performance of activity of individual brain regions. In certain cases, there is no activity in a brain region, which we excluded from our data in later function.  "
      ],
      "metadata": {
        "id": "8GESXL808xuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_corr_coef_matrix(brain_region1, brain_region2, brain_region3):\n",
        "  \"\"\"\n",
        "  Obtains the correlation matrix between three brain regions\n",
        "    Arguments:\n",
        "      brain_region1: (lst) the indices of specific brain region \n",
        "      brain_region2: (lst) the indices of specific brain region \n",
        "      brain_region3: (lst) the indices of specific brain region \n",
        "    Returns:\n",
        "      Correlation matrix between three brain regions \n",
        "  \"\"\"\n",
        "\n",
        "  # Create an empty matrix to store the correlation matrix per trial \n",
        "  corr_coef_matrix_all_trials = np.zeros((len(trials['stimOn_times']), 6))\n",
        "\n",
        "  # Load data in bins \n",
        "  ts = trials['stimOn_times'] + np.linspace(-.4,0,20).reshape((-1,1))\n",
        "  ts = ts.T\n",
        "  intervals = np.vstack((np.ndarray.flatten(ts[:,0:-1]), np.ndarray.flatten(ts[:,1:]))).T\n",
        "\n",
        "  matrix, cluster_ids_out = decode.get_spike_counts_in_bins(spikes['times'],\n",
        "                                                          spikes['clusters'],\n",
        "                                                          intervals=intervals)\n",
        "\n",
        "  for i in range(len(trials['stimOn_times'])):\n",
        "  \n",
        "    # Calculate the mean activity of the brain region at each time\n",
        "    brain_region_activity1 = np.mean(np.take(matrix[:, i*19:(i+1)*19], indices=brain_region1, axis=0), axis=0)\n",
        "    brain_region_activity2 = np.mean(np.take(matrix[:, i*19:(i+1)*19], indices=brain_region2, axis=0), axis=0)\n",
        "    brain_region_activity3 = np.mean(np.take(matrix[:, i*19:(i+1)*19], indices=brain_region3, axis=0), axis=0)\n",
        "\n",
        "    # Calculate the correlation matrix\n",
        "    corr_coef_matrix = np.corrcoef((np.stack((brain_region_activity1, \n",
        "                                            brain_region_activity2, brain_region_activity3),axis=0)))\n",
        "\n",
        "    # Replace diagonal with the average activity across time \n",
        "    corr_coef_matrix[0,0] = float(np.mean(np.take(matrix[:, i*19:(i+1)*19], indices=brain_region1, axis=0)))\n",
        "    corr_coef_matrix[1,1] = float(np.mean(np.take(matrix[:, i*19:(i+1)*19], indices=brain_region2, axis=0)))\n",
        "    corr_coef_matrix[2,2] = float(np.mean(np.take(matrix[:, i*19:(i+1)*19], indices=brain_region3, axis=0)))\n",
        "\n",
        "    # Find the upper triangle matrix\n",
        "    corr_coef_matrix_no_zero = np.triu(corr_coef_matrix)\n",
        "\n",
        "    # Remove 0 from the upper triangle matrix\n",
        "    corr_coef_matrix_per_trial = corr_coef_matrix_no_zero[corr_coef_matrix_no_zero != 0]\n",
        "\n",
        "    try:\n",
        "      # Store the correlation matrix \n",
        "      corr_coef_matrix_all_trials[i] = corr_coef_matrix_per_trial \n",
        "    except: \n",
        "      continue\n",
        "\n",
        "  return corr_coef_matrix_all_trials\n"
      ],
      "metadata": {
        "id": "ScZwRyN-o1uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An alternate version of the code above. This function calculates the correlation coefficient matrix of two brain regions. "
      ],
      "metadata": {
        "id": "PA5KcDvelsbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_corr_coef_matrix_two_regions(brain_region1, brain_region2):\n",
        "  \"\"\"\n",
        "  Obtains the correlation matrix between two brain regions\n",
        "    Arguments:\n",
        "      brain_region1: (lst) the indices of specific brain region \n",
        "      brain_region2: (lst) the indices of specific brain region \n",
        "    Returns:\n",
        "      Correlation matrix between two brain regions \n",
        "  \"\"\"\n",
        "\n",
        "  corr_coef_matrix_all_trials = np.zeros((len(trials['stimOn_times']), 3))\n",
        "\n",
        "  ts = trials['stimOn_times'] + np.linspace(-.4,0,20).reshape((-1,1))\n",
        "  ts = ts.T\n",
        "  intervals = np.vstack((np.ndarray.flatten(ts[:,0:-1]), np.ndarray.flatten(ts[:,1:]))).T\n",
        "\n",
        "  matrix, cluster_ids_out = decode.get_spike_counts_in_bins(spikes['times'],\n",
        "                                                          spikes['clusters'],\n",
        "                                                          intervals=intervals)\n",
        "\n",
        "  for i in range(len(trials['stimOn_times'])):\n",
        "  \n",
        "    brain_region_activity1 = np.mean(np.take(matrix[:, i*19:(i+1)*19], indices=brain_region1, axis=0), axis=0)\n",
        "    brain_region_activity2 = np.mean(np.take(matrix[:, i*19:(i+1)*19], indices=brain_region2, axis=0), axis=0)\n",
        "\n",
        "    corr_coef_matrix = np.corrcoef((np.stack((brain_region_activity1, \n",
        "                                            brain_region_activity2),axis=0)))\n",
        "\n",
        "    corr_coef_matrix[0,0] = float(np.mean(np.take(matrix[:, i*19:(i+1)*19], indices=brain_region1, axis=0)))\n",
        "    corr_coef_matrix[1,1] = float(np.mean(np.take(matrix[:, i*19:(i+1)*19], indices=brain_region2, axis=0)))\n",
        "\n",
        "    corr_coef_matrix_no_zero = np.triu(corr_coef_matrix)\n",
        "  \n",
        "    corr_coef_matrix_per_trial = corr_coef_matrix_no_zero[corr_coef_matrix_no_zero != 0]\n",
        "\n",
        "    try:\n",
        "      corr_coef_matrix_all_trials[i] = corr_coef_matrix_per_trial \n",
        "    except: \n",
        "      continue\n",
        "\n",
        "  return corr_coef_matrix_all_trials\n"
      ],
      "metadata": {
        "id": "26Pn4BqIPBEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We trained the logistic regression function on correlation of brain regions and feedback type. The function predicts weights based on feedback type or error, which indicates whether the mice received a reward or no reward. The function also removes rows with no activity from the correlation coefficient matrix and the feedback type because it will interfere with our prediction."
      ],
      "metadata": {
        "id": "MIiAzKgMl2QF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression(corr_coef_matrix_all_trials):\n",
        "  \"\"\"\n",
        "  Logistic regression on the correlation matrix \n",
        "    Arguments:\n",
        "      corr_coef_matrix_all_trials: (array) correlation matrix \n",
        "    Returns:\n",
        "      Accuracy, predicted, probability, null model, and coefficients of the \n",
        "      regression, and edited X and y matrix\n",
        "  \"\"\"\n",
        "\n",
        "  # Replace -1 error with 0 #Bug: feedback contains -1's: this causes your null model to have a lower value (~.64) than the mouse performance (~.82)\n",
        "  feedback = trials['feedbackType'] #better to pass 'trials' as an input to function rather than relying on global value: GA\n",
        "  # choice[choice == -1] = 0 \n",
        "  #commenting the following line out - this matrix is already provided by the input argument to this function!: GA\n",
        "  #X = get_corr_coef_matrix(VIS_neurons, CA1_neurons, PO_neurons) #VIS_neurons etc are globally defined, better to pass as arguments: GA\n",
        "  X = corr_coef_matrix_all_trials #I added this line instead, since you already have this matrix defined: GA\n",
        "  Z = np.zeros((len(trials['stimOn_times']), 6))\n",
        "\n",
        "  # Find 0 or nan in the correlation matrix\n",
        "  X[:] == Z #This line seems extra: GA\n",
        "  where_to_remove = np.where(np.all(X==Z, axis=1)) #can use X==0 instead of defining Z: GA\n",
        "\n",
        "  # Remove rows with no activity in the correlation matrix\n",
        "  remove_no_activity = np.delete(X[:], where_to_remove, axis=0) \n",
        "  remove_no_choice = np.delete(feedback[:], where_to_remove, axis=0)\n",
        "\n",
        "  # Results of the regression with cross validation \n",
        "  classifier = LogisticRegression(max_iter=1e4)\n",
        "  cross_validation = KFold(n_splits=5)\n",
        "  acc, pred, prob = decode.classify(remove_no_activity,\n",
        "                                  remove_no_choice, \n",
        "                                  classifier,\n",
        "                                  cross_validation=cross_validation)\n",
        "    \n",
        "  # Null model \n",
        "  null = np.mean(remove_no_choice)\n",
        "\n",
        "  # Store predicted coefficients\n",
        "  glm = classifier.fit(remove_no_activity, remove_no_choice)\n",
        "\n",
        "  return acc, pred, prob, null, glm\n"
      ],
      "metadata": {
        "id": "FwtMUYvJqKOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "Runs the logistic regression over all 83 sessions. We excluded some sessions because they do not have trials data. "
      ],
      "metadata": {
        "id": "QUXqeHrMl7sP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interestingly, the plot appears to have a normally distributed curve. This happens by chance alone because the K-Fold cross-validation splits into 5. \n",
        "\n",
        "**The code has major bugs that invalidate the results. 1. spikes and clusters need to be loaded anew for each session. Identities of VIS/CA1/PO neurons needs to be loaded for each session. The way the code is now, the neural activity from session 1 is being used to predict the behavior of the mice across all sessions. In addition, several functions are unnecessarily duplicated, so that the same code is being run multiple times: GA**"
      ],
      "metadata": {
        "id": "YYAFeEcFBQqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accdata = []\n",
        "nulldata = []\n",
        "\n",
        "glms = []\n",
        "\n",
        "for i in range(83): \n",
        "  #it is dangerous to put a 'try' here because the code will keep running even if there are bugs: GA\n",
        "  #try: \n",
        "    # Iterate over mutiple sessions \n",
        "  trials = one.load_object(one.pid2eid(pids[i])[0], 'trials')\n",
        "  ''' Removing the following lines as they are already called within get_corr_coef_matrix: GA\n",
        "  corr_coef_matrix_all_trials = np.zeros((len(trials['stimOn_times']), 6))\n",
        "\n",
        "  ts = trials['stimOn_times'] + np.linspace(-.4,0,20).reshape((-1,1))\n",
        "  ts = ts.T\n",
        "  intervals = np.vstack((np.ndarray.flatten(ts[:,0:-1]), np.ndarray.flatten(ts[:,1:]))).T\n",
        "\n",
        "  matrix, cluster_ids_out = decode.get_spike_counts_in_bins(spikes['times'],\n",
        "                                                        spikes['clusters'],\n",
        "                                                        intervals=intervals)\n",
        "  '''\n",
        "  #Bug: VIS/CA1/PO neurons need to be reassigned for each new session!: GA\n",
        "  #Bug: spikes matrix needs to be reassigned for each new session!: GA\n",
        "  X = get_corr_coef_matrix(VIS_neurons, CA1_neurons, PO_neurons)\n",
        "      \n",
        "  acc, pred, prob, null, glm = logistic_regression(X)\n",
        "\n",
        "  # Append data for later anaylsis \n",
        "  accdata.append(acc)\n",
        "  # Prevent null model from predicting low \n",
        "  nulldata.append(max(null, 1-null))\n",
        "  glms.append(glm) \n",
        "\n",
        "  # Comment out to see plots for each sesssion \n",
        "  #plt.figure(figsize=(12,4))\n",
        "  #plt.title(f'Session {i+1} \\nPredicting Activity: accuracy of {acc:.3f}         ')\n",
        "\n",
        "  #plt.plot(prob, 'o')\n",
        "  #plt.ylabel('Predicted Prob. Correct')\n",
        "  #plt.xlabel('Number of Trials')\n",
        "  #plt.show()\n",
        "  #print('')\n",
        "  #commenting the next 2 lines as 'feedback' is undefined: GA\n",
        "  #if feedback == 0:\n",
        "  #  print(\"matrix has a 0!\")\n",
        "\n",
        "  #except:\n",
        "    #continue\n",
        " "
      ],
      "metadata": {
        "id": "NE3k7o_uh4LV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4e4220c4-2677-4342-bbe2-b1f3a2430e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80f6ffdd-f692-450f-ab19-cd6d45bfd73e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[:, None]\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[None, :]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27bac116-ea57-4512-ad35-714a62d259cd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[:, None]\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[None, :]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02cc03e4-8015-4050-bb42-6c832091febb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[:, None]\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[None, :]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f9d8aacd-b2a0-49f2-bd71-c2f5aadcfdd1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[:, None]\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[None, :]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9e44ddb5-7c7c-48f1-954a-6cec2ad26088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[:, None]\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[None, :]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e49f221d-399d-4297-bb7d-2d23cc0e4acc\n",
            "94e948c1-f7be-4868-893a-f7cd2df3313e\n",
            "d7361c6f-6751-4b5f-91c2-fdd61f988aa4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[:, None]\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[None, :]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ALFObjectNotFound",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mALFObjectNotFound\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-64514003587e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Iterate over mutiple sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid2eid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trials'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   ''' Removing the following lines as they are already called within get_corr_coef_matrix: GA\n\u001b[1;32m     13\u001b[0m   \u001b[0mcorr_coef_matrix_all_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stimOn_times'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/one/util.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/one/util.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, id, *args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Cannot parse session ID \"{id}\" (session may not exist)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/one/api.py\u001b[0m in \u001b[0;36mload_object\u001b[0;34m(self, eid, obj, collection, revision, query_type, download_only, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m         \u001b[0;31m# Validate result before loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0malferr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALFObjectNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrel_path_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrel_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0munique_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mALFObjectNotFound\u001b[0m: trials \n The ALF object was not found.  This may occur if the object or namespace or incorrectly formatted e.g. the object \"_ibl_trials.intervals.npy\" would be found with the filters `object=\"trials\", namespace=\"ibl\"` "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mean accuracy over sessions gives the accuracy of our model over all 83 sessions. The null over sessions similarly gives the null model accuracy over all 83 sessions. The p-value compares our predicted weights over all 83 sessions and the null hypothesis. The p-value for the visual cortex and the correlation between the visual cortex and the CA1 hippocampus is insignifcant, however, is fairly low compared to other p-values. The distribution of the first weight is skewed away from 0. It is possible that for greater number of sessions, we may be able to see a significant difference between the weights and the null hypothesis for the visual cortex, and possibly the visual cortex and hippocampus. This result may arise because the mice uses the visual cortex to see and the hippocampus too differentiate the contrasts from memory. There is a primed sense of sensitivty of neurons in the visual cortex as well as in the hippocampus to retrive memory."
      ],
      "metadata": {
        "id": "sWGDnlAomBQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "#print(np.array(accdata))\n",
        "print((f'Mean accuracy over sessions: {np.mean(accdata):3f}'))\n",
        "\n",
        "#print(np.array(nulldata))\n",
        "print((f'Null model over sessions: {np.mean(nulldata):3f}'))\n",
        "\n",
        "all_coefs = np.zeros((67, 6))\n",
        "\n",
        "# Index the weight of all successful sessions  \n",
        "for i in range(67):\n",
        "\n",
        "  all_coefs[i] = glms[i].coef_\n",
        "\n",
        "# Calculate the mean and the standard error \n",
        "mean = np.mean(all_coefs, axis=0)\n",
        "std_error = np.std(all_coefs) / np.sqrt(len(all_coefs))\n",
        "\n",
        "# Calculate the t-statistics, known mean is 0 \n",
        "t = abs(mean) / std_error\n",
        "\n",
        "t_critical_value = stats.t.ppf(q=0.975, df=11) #shouldn't df = 67-1 = 66? : GA\n",
        "\n",
        "p_value = 2*(1-stats.t.cdf(x=t, df=11))\n",
        "# using the following line, I get a different p-value: GA\n",
        "_,p_value1 = stats.ttest_1samp(all_coefs,popmean=0,axis=0)\n",
        "#print(f't_critical_value for session {i+1}: {t_critical_value}')\n",
        "print(f'p_values: {p_value}')\n",
        "print(f'p_values (GA): {p_value1}')\n",
        "\n",
        "# Plots histograms for predicted weights for our 6 regressors\n",
        "figure, axis = plt.subplots(6, figsize=(10,12))\n",
        "figure.tight_layout()\n",
        "\n",
        "for i in range(6):\n",
        "  counts, bins = np.histogram(all_coefs[:,i])\n",
        "  axis[i].set_xlabel('Predicted Weights')\n",
        "  axis[i].set_ylabel('Counts')\n",
        "  axis[i].hist(bins[:-1], bins, weights=counts)\n"
      ],
      "metadata": {
        "id": "8UkhiAipocKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plots the p-values over trials. The p-value for the first two coefficients reached close to signficant levels. For greater number of sessionos, we may see more signficance between the null model and our model."
      ],
      "metadata": {
        "id": "lzzmon3F7JCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p_values = []\n",
        "\n",
        "all_coefs = np.zeros((67, 6))\n",
        "\n",
        "# Index the weight of all successful sessions  \n",
        "for i in range(67):\n",
        "\n",
        "  all_coefs[i] = glms[i].coef_\n",
        "\n",
        "  mean = np.mean(all_coefs, axis=0)\n",
        "  std_error = np.std(all_coefs) / np.sqrt(len(all_coefs))\n",
        "  # Calculate the t-statistics, known mean is 0 \n",
        "  t = abs(mean) / std_error\n",
        "\n",
        "  t_critical_value = stats.t.ppf(q=0.975, df=11)\n",
        "\n",
        "  p_value = 2*(1-stats.t.cdf(x=t, df=11))\n",
        "\n",
        "  p_values.append(p_value) \n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.plot(p_values)\n",
        "plt.ylabel('P-value')\n",
        "plt.xlabel('Number of Sessions')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "coENr0AIrv6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional investigations\n",
        "In addition to logistic regression for three brain regions, we explored if there were any significant differences in accuracy if we ran the regression with two brain regions.  "
      ],
      "metadata": {
        "id": "ot9g1r9GTayh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Runs the logistic regression for two brain region over 83 sessions. The sets of brain regions are the visual cortex and CA1 hippocampus, CA1 hippocampus and thalamus, and visual cortext and thalamus. **This doesnt seem like a useful analysis - since the previous 3-region regression didn't work, it is unlikely that this would work: GA**"
      ],
      "metadata": {
        "id": "wxZrbeFzBldb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Empty lists to store data for accuracy, null model, and coefficients\n",
        "accdata_VIS_CA1 = []\n",
        "nulldata_VIS_CA1 = []\n",
        "glms_VIS_CA1 = []\n",
        "\n",
        "accdata_CA1_PO = []\n",
        "nulldata_CA1_PO = []\n",
        "glms_CA1_PO = []\n",
        "\n",
        "accdata_VIS_PO = []\n",
        "nulldata_VIS_PO = []\n",
        "glms_VIS_PO = []\n",
        "\n",
        "for i in range(83): \n",
        "  try: \n",
        "    trials = one.load_object(one.pid2eid(pids[i])[0], 'trials')\n",
        "\n",
        "    corr_coef_matrix_all_trials = np.zeros((len(trials['stimOn_times']), 3))\n",
        "\n",
        "    ts = trials['stimOn_times'] + np.linspace(-.4,0,20).reshape((-1,1))\n",
        "    ts = ts.T\n",
        "    intervals = np.vstack((np.ndarray.flatten(ts[:,0:-1]), np.ndarray.flatten(ts[:,1:]))).T\n",
        "\n",
        "    matrix, cluster_ids_out = decode.get_spike_counts_in_bins(spikes['times'],\n",
        "                                                          spikes['clusters'],\n",
        "                                                          intervals=intervals)\n",
        "  \n",
        "    # Calculate the accuracy, predicted, probability predicted, null model, and the coefficients of logistic regression ran on two brain regions\n",
        "    acc1, pred1, prob1, null1, glm1 = logistic_regression(get_corr_coef_matrix_two_regions(VIS_neurons, CA1_neurons))\n",
        "    acc2, pred2, prob2, null2, glm2 = logistic_regression(get_corr_coef_matrix_two_regions(CA1_neurons, PO_neurons))\n",
        "    acc3, pred3, prob3, null3, glm3 = logistic_regression(get_corr_coef_matrix_two_regions(VIS_neurons, PO_neurons))\n",
        "\n",
        "    # Append data onto the empty list \n",
        "    accdata_VIS_CA1.append(acc1)\n",
        "    nulldata_VIS_CA1.append(max(null1, 1-null1))\n",
        "\n",
        "    accdata_CA1_PO.append(acc2)\n",
        "    nulldata_CA1_PO.append(max(null2, 1-null2))\n",
        "\n",
        "    accdata_VIS_PO.append(acc3)\n",
        "    nulldata_VIS_PO.append(max(null3, 1-null3))\n",
        "\n",
        "    glms_VIS_CA1.append(glm1)\n",
        "    glms_CA1_PO.append(glm2)\n",
        "    glms_VIS_PO.append(glm3)\n",
        "\n",
        "  except:\n",
        "    continue\n",
        "\n"
      ],
      "metadata": {
        "id": "riRHKY1kPPSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prints the accuracy and the null model for the logistic regression ran on sets of brain regions over mutiple sessions. The definition of mean accuracy and null is the same as above. While the accuracy for the corrleation between two brain regions is higher than the null model, the accuracy is the same with other sets of brain regions. This results is because the accuracy is matching chance levels. **The null model is artificially lower because your 'feedback' vector has -1/1 instead of 0/1: GA**"
      ],
      "metadata": {
        "id": "JxTaseLMoy58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the accuracy and null model results of our regression \n",
        "print(np.array(accdata_VIS_CA1))\n",
        "print((f'Mean accuracy over sessions: {np.mean(accdata_VIS_CA1):3f}'))\n",
        "#print(np.array(nulldata_VIS_CA1))\n",
        "print((f'Null over sessions: {np.mean(nulldata_VIS_CA1):3f}'))\n",
        "\n",
        "print(np.array(accdata_CA1_PO))\n",
        "print((f'Mean accuracy over sessions: {np.mean(accdata_CA1_PO):3f}'))\n",
        "#print(np.array(nulldata_CA1_PO))\n",
        "print((f'Null over sessions: {np.mean(nulldata_CA1_PO):3f}'))\n",
        "\n",
        "print(np.array(accdata_VIS_PO))\n",
        "print((f'Mean accuracy over sessions: {np.mean(accdata_VIS_PO):3f}'))\n",
        "#print(np.array(nulldata_VIS_PO))\n",
        "print((f'Null over sessions: {np.mean(nulldata_VIS_PO):3f}'))"
      ],
      "metadata": {
        "id": "IzNP-NrcQSHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The coef_t_test function calculates the t-test results for the predicted weights. The plot_coef function plots the predicted weights distribution over all 83 sessions. "
      ],
      "metadata": {
        "id": "Q4ZPXqHHGe2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def coef_t_test(glms):\n",
        "\n",
        "  for i in range(67):\n",
        "    all_coefs[i] = glms[i].coef_\n",
        "\n",
        "  mean = np.mean(all_coefs, axis=0)\n",
        "  std_error = np.std(all_coefs) / np.sqrt(len(all_coefs))\n",
        "\n",
        "  # Calculate the t-statistics, known mean is 0\n",
        "  t = abs(mean) / std_error\n",
        "\n",
        "  t_critical_value = stats.t.ppf(q=0.975, df=11)\n",
        "\n",
        "  p_value = 2*(1-stats.t.cdf(x=t, df=11))\n",
        "\n",
        "  #print(f't_critical_value for session {i+1}: {t_critical_value}')\n",
        "  print(f'p_values: {p_value}')\n",
        "\n",
        "def plot_coefs(glms):\n",
        "\n",
        "  for i in range(6):\n",
        "    all_coefs[i] = glms[i].coef_\n",
        "\n",
        "  figure, axis = plt.subplots(6, figsize=(10,12))\n",
        "  figure.tight_layout()\n",
        "\n",
        "  # Plot histograms \n",
        "  for i in range(6):\n",
        "    counts, bins = np.histogram(all_coefs[:,i])\n",
        "    axis[i].set_xlabel('Predicted Weights')\n",
        "    axis[i].set_ylabel('Counts')\n",
        "    axis[i].hist(bins[:-1], bins, weights=counts)\n"
      ],
      "metadata": {
        "id": "_X_1Aox4ERco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The t-test results for all sets of two brain regions. The p-values are exactly similar to each other because the results are only from chance."
      ],
      "metadata": {
        "id": "2zE2fufXGtqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coef_t_test(glms_VIS_CA1)\n",
        "coef_t_test(glms_CA1_PO)\n",
        "coef_t_test(glms_VIS_PO)"
      ],
      "metadata": {
        "id": "oqUCmwF8FrJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plots the histogram of our coefficients from the logistic regression on different sets of two brain regions. All the histograms were similar. "
      ],
      "metadata": {
        "id": "IQGfePtSp6sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_coefs(glms_VIS_CA1)"
      ],
      "metadata": {
        "id": "yd9vq0m1FrtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_coefs(glms_CA1_PO)"
      ],
      "metadata": {
        "id": "DIZdsNS1FsDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_coefs(glms_VIS_PO)"
      ],
      "metadata": {
        "id": "eTSBgPXlFseZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA of one sessions. We ran PCA to test the accuracy of our model for one session. The accuracy did not improve significantly from our model. "
      ],
      "metadata": {
        "id": "DGj6fs9UBpf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variance decreases after first principal component. There is a significant correlation between brain regions before movement. The first principal component is capturing large changes in global brain activity. Research has indicated tweaking in whiskers results in increased variance explained for the first few principal components."
      ],
      "metadata": {
        "id": "aBUOV5XOIqLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Index the probe of the first session \n",
        "trials = one.load_object(one.pid2eid(pids[0])[0], 'trials')\n",
        "\n",
        "# Replace no reward with 0 fo regression \n",
        "y = trials['feedbackType']\n",
        "y[y == -1] = 0  \n",
        "\n",
        "matrix, cluster_ids_out = decode.get_spike_counts_in_bins(spikes['times'], \n",
        "                                                          spikes['clusters'], \n",
        "                                                          intervals=np.vstack((trials['stimOn_times'] - 0.4, trials['stimOn_times'])).T)\n",
        "\n",
        "\n",
        "# Index the brain region activity \n",
        "brain_region_activity1 = np.take(matrix, indices=VIS_neurons, axis=0)\n",
        "brain_region_activity2 = np.take(matrix, indices=CA1_neurons, axis=0)\n",
        "brain_region_activity3 = np.take(matrix, indices=PO_neurons, axis=0)\n",
        "\n",
        "# Combine the brain region activity for PCA \n",
        "X = np.vstack((brain_region_activity1, brain_region_activity2, brain_region_activity3))\n",
        "\n",
        "X = X - np.reshape(np.mean(X,axis=1),(X.shape[0],1))\n",
        "\n",
        "w_c, v_c = np.linalg.eig(np.matmul(X,X.T))\n",
        "w_t, v_t = np.linalg.eig(np.matmul(X.T,X))\n",
        "\n",
        "plt.figure(figsize=(8,3))\n",
        "plt.plot(w_c/np.sum(w_c),lw=3)\n",
        "# plt.plot(w_t/np.sum(w_t),lw=3) # verified that this gives the same as above\n",
        "plt.ylabel('Var. Explained \\n(frac. of total var.)')\n",
        "plt.xlabel('Index of PC (Principle Component)')\n",
        "plt.ylim(0, 0.5)\n",
        "plt.xscale('log') \n",
        "plt.show()\n",
        "print('')\n",
        "\n",
        "NPCs = 3\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "for i in range(NPCs):\n",
        "  plt.plot(v_c[:,i])\n",
        "# plt.legend([f'PC {pi}' for pi in range(NPCs)], fontsize=12)\n",
        "plt.legend(['PC A', 'PC B', 'PC C'], fontsize=15)\n",
        "plt.ylabel('PC Weights')\n",
        "plt.xlabel('Cluster ID')\n",
        "plt.show()\n",
        "print('')\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "for i in range(NPCs):\n",
        "  plt.plot(v_t[:,i])\n",
        "plt.legend([f'PC {pi}' for pi in range(NPCs)], fontsize=12)\n",
        "plt.ylabel('PC Weights')\n",
        "plt.xlabel('Number of Trials')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "D91NlcC1ozzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The PCA results. PCA did not improve the accuracy signficantly from the test. Similarly, the PCA result was not signficantly better than the our logistic regression from results. **Has the same bug as earlier - the spikes and brain region identities are being pulled from session 1: GA**"
      ],
      "metadata": {
        "id": "iB4CrrL3H0r-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for i in range(12):\n",
        "  try:\n",
        "    # Iterate over mutiple sessions \n",
        "    trials = one.load_object(one.pid2eid(pids[i])[0], 'trials')\n",
        "\n",
        "    y = trials['feedbackType']\n",
        "    y[y == -1] = 0  \n",
        "\n",
        "    matrix, cluster_ids_out = decode.get_spike_counts_in_bins(spikes['times'], \n",
        "                                                        spikes['clusters'], \n",
        "                                                        intervals=np.vstack((trials['stimOn_times'] - 0.4, trials['stimOn_times'])).T)\n",
        "\n",
        "\n",
        "    brain_region_activity1 = np.take(matrix, indices=VIS_neurons, axis=0)\n",
        "    brain_region_activity2 = np.take(matrix, indices=CA1_neurons, axis=0)\n",
        "    brain_region_activity3 = np.take(matrix, indices=PO_neurons, axis=0)\n",
        "\n",
        "    X = np.vstack((brain_region_activity1, brain_region_activity2, brain_region_activity3)).T\n",
        "\n",
        "    # Process X matrix \n",
        "    sc = StandardScaler()\n",
        "    X_scaled = sc.fit_transform(X)\n",
        "\n",
        "    # Apply PCA\n",
        "    pca = PCA(n_components=6)\n",
        "    X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "    split = y.shape[0]\n",
        "\n",
        "    X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca[:split,:], y, test_size=0.20, \n",
        "                                                          shuffle=True, random_state=2)\n",
        "\n",
        "    clf = LogisticRegression(max_iter=1e14)\n",
        "\n",
        "    clf.fit(X_train_pca, y_train)\n",
        "\n",
        "    # Make predictions based on logistic regression \n",
        "    y_pred = clf.predict(X_test_pca)  \n",
        "    y_true = y_test # True values \n",
        "\n",
        "    print(\"Train accuracy:\", np.round(accuracy_score(y_train, \n",
        "                                                clf.predict(X_train_pca)), 5))\n",
        "    print(\"Test accuracy:\", np.round(accuracy_score(y_true, y_pred), 5))\n",
        "  \n",
        "  except:\n",
        "    continue"
      ],
      "metadata": {
        "id": "Rqe81-69pNAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional comments: \n",
        "* your approach was systematic but the results cannot be interpreted because session 1 spiking data was used for regression in each of the other sessions.\n",
        "* there was significant redundancy in the code so that the same operations were being performed across different chunks of code.\n",
        "* bibliography was requested to be included in this notebook.\n",
        "* The analysis of pairwise correlations seems unnecessary in light of the regressions done with the 3-region correlation\n",
        "* statistics are erroneous, based on incorrect degrees of freedom\n",
        "* Lindenbach reference does not indicate journal source - couldn't be located. Appears to be using an unrelated task, which doesn't seem to indicate whether PO would be involved in the current study.\n",
        "\n",
        "Oral:\n",
        "Oral/Visual/Background/Hypothesis/Methods/Results/Discussion\n",
        "max: 10/10/12/4/12/12/10 = 70\n",
        "* Guido: 9/8/11/3.5/10/8/9 = 58.5\n",
        "* Julia: 8/8/10/3.5/8/8/9 = 54.5\n",
        "80.7%\n",
        "\n",
        "Written:\n",
        "Notebook: 10/10\n",
        "Coding: 5/10\n",
        "Analysis: 16/20\n",
        "Bibliography: 8/10\n",
        "Total: 39/50\n",
        "78%\n",
        "\n",
        "total: 7.94/10"
      ],
      "metadata": {
        "id": "p5ShfeIfZ95f"
      }
    }
  ]
}